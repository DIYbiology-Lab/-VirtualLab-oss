FROM vllm/vllm-openai:latest
ARG MODEL_ID=openai/gpt-oss-20b
ENV HF_HUB_ENABLE_HF_TRANSFER=1 MODEL_DIR=/models/gpt-oss
RUN pip install -U "huggingface_hub[cli]"
RUN huggingface-cli download "${MODEL_ID}" --include "original/*" --local-dir "${MODEL_DIR}"
EXPOSE 8000
ENV SERVED_MODEL_NAME=${MODEL_ID}
CMD bash -lc 'vllm serve "$MODEL_DIR" --host 0.0.0.0 --port 8000 --served-model-name "$SERVED_MODEL_NAME" --gpu-memory-utilization 0.90 --max-model-len 32768'